{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting pgl\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/e2/84/6aac242f80a794f1169386d73bdc03f2e3467e4fa85b1286979ddf51b1a0/pgl-1.2.1-cp37-cp37m-manylinux1_x86_64.whl (7.9MB)\n",
      "\u001b[K     |████████████████████████████████| 7.9MB 13.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting easydict\n",
      "  Downloading https://mirror.baidu.com/pypi/packages/4c/c5/5757886c4f538c1b3f95f6745499a24bffa389a805dee92d093e2d9ba7db/easydict-1.9.tar.gz\n",
      "Requirement already satisfied: cython>=0.25.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (0.29)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (1.16.4)\n",
      "Requirement already satisfied: visualdl>=2.0.0b; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (2.1.1)\n",
      "Collecting redis-py-cluster (from pgl)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/2b/c5/3236720746fa357e214f2b9fe7e517642329f13094fc7eb339abd93d004f/redis_py_cluster-2.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 22.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.21.0)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.0.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.8.53)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.7.1.1)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.1.1)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (7.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.15.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (3.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.22.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl) (3.14.0)\n",
      "Collecting redis<4.0.0,>=3.0.0 (from redis-py-cluster->pgl)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 20.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.4.10)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.23)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (5.1.2)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.0.1)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.3.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.3.4)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (16.7.9)\n",
      "Requirement already satisfied: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.10.1)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2019.3)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.18.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.16.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (7.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.2.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.6.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (1.1.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl) (7.2.0)\n",
      "Building wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for easydict: filename=easydict-1.9-cp37-none-any.whl size=6350 sha256=9cd44225ba5c8576e092155163212584d79b2b3b0168592deff31db2af077d36\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/35/8b/38/7327c27cd3d4590ffa75b98030bd3828e68b8bb3d599573163\n",
      "Successfully built easydict\n",
      "Installing collected packages: redis, redis-py-cluster, pgl, easydict\n",
      "Successfully installed easydict-1.9 pgl-1.2.1 redis-3.5.3 redis-py-cluster-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pgl easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56188, 1)\n",
      "(35117, 1)\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\r\n",
    "import pgl\r\n",
    "import paddle.fluid as fluid\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import random\r\n",
    "from easydict import EasyDict as edict\r\n",
    "\r\n",
    "config = {\r\n",
    "    \"model_name\": \"UNIMAP_label_embedding\",\r\n",
    "    \"num_layers\":3,\r\n",
    "    \"dropout\": 0.3,\r\n",
    "    \"learning_rate\": 0.001,\r\n",
    "    \"weight_decay\": 0.0005,\r\n",
    "}\r\n",
    "\r\n",
    "config = edict(config)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "Dataset = namedtuple(\"Dataset\", \r\n",
    "               [\"graph\", \"num_classes\", \"train_index\",\r\n",
    "                \"train_label\", \"valid_index\", \"valid_label\", \"test_index\"])\r\n",
    "\r\n",
    "def load_edges(num_nodes, self_loop=True, add_inverse_edge=True):\r\n",
    "    # 从数据中读取边\r\n",
    "    edges = pd.read_csv(\"data/data61620/edges.csv\", header=None, names=[\"src\", \"dst\"]).values\r\n",
    "\r\n",
    "    if add_inverse_edge:\r\n",
    "        edges = np.vstack([edges, edges[:, ::-1]])\r\n",
    "\r\n",
    "    if self_loop:\r\n",
    "        src = np.arange(0, num_nodes)\r\n",
    "        dst = np.arange(0, num_nodes)\r\n",
    "        self_loop = np.vstack([src, dst]).T\r\n",
    "        edges = np.vstack([edges, self_loop])\r\n",
    "    \r\n",
    "    return edges\r\n",
    "\r\n",
    "def load():\r\n",
    "    # 从数据中读取点特征和边，以及数据划分\r\n",
    "    node_feat = np.load(\"data/data61620/feat.npy\")\r\n",
    "    num_nodes = node_feat.shape[0]\r\n",
    "    edges = load_edges(num_nodes=num_nodes, self_loop=True, add_inverse_edge=True)\r\n",
    "    graph = pgl.graph.Graph(num_nodes=num_nodes, edges=edges, node_feat={\"feat\": node_feat})\r\n",
    "    \r\n",
    "    indegree = graph.indegree()\r\n",
    "    norm = np.maximum(indegree.astype(\"float32\"), 1)\r\n",
    "    norm = np.power(norm, -0.5)\r\n",
    "    graph.node_feat[\"norm\"] = np.expand_dims(norm, -1)\r\n",
    "    \r\n",
    "    df = pd.read_csv(\"data/data61620/train.csv\")\r\n",
    "    node_idx = df[\"nid\"].values\r\n",
    "    node_label = df[\"label\"].values\r\n",
    "    train_part = int(len(node_idx) * 0.8)\r\n",
    "    train_index = node_idx[:train_part]\r\n",
    "    train_label = node_label[:train_part]\r\n",
    "    valid_index = node_idx[train_part:]\r\n",
    "    valid_label = node_label[train_part:]\r\n",
    "    test_index = pd.read_csv(\"data/data61620/test.csv\")[\"nid\"].values\r\n",
    "    dataset = Dataset(graph=graph, \r\n",
    "                    train_label=train_label,\r\n",
    "                    train_index=train_index,\r\n",
    "                    valid_index=valid_index,\r\n",
    "                    valid_label=valid_label,\r\n",
    "                    test_index=test_index, num_classes=35)\r\n",
    "    return dataset\r\n",
    "\r\n",
    "dataset = load()\r\n",
    "\r\n",
    "test_index = dataset.test_index\r\n",
    "test_index = np.expand_dims(test_index, -1)\r\n",
    "test_label = np.zeros((len(test_index), 1), dtype=\"int64\")\r\n",
    "\r\n",
    "val_index = dataset.valid_index\r\n",
    "val_label = np.reshape(dataset.valid_label, [-1, 1])\r\n",
    "val_index = np.expand_dims(val_index, -1)\r\n",
    "\r\n",
    "train_index = dataset.train_index\r\n",
    "train_label = np.reshape(dataset.train_label, [-1 , 1])\r\n",
    "train_index = np.expand_dims(train_index, -1)\r\n",
    "print(train_label.shape)\r\n",
    "print(train_index[:int(len(train_index)*0.625)].shape)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "def linear(input, hidden_size, name, with_bias=True):\r\n",
    "    \"\"\"linear\"\"\"\r\n",
    "    fan_in=input.shape[-1]\r\n",
    "    bias_bound = 1.0 / math.sqrt(fan_in)\r\n",
    "    if with_bias:\r\n",
    "        fc_bias_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-bias_bound, high=bias_bound))\r\n",
    "    else:\r\n",
    "        fc_bias_attr = False\r\n",
    "        \r\n",
    "    negative_slope = math.sqrt(5)\r\n",
    "    gain = math.sqrt(2.0 / (1 + negative_slope ** 2))\r\n",
    "    std = gain / math.sqrt(fan_in)\r\n",
    "    weight_bound = math.sqrt(3.0) * std\r\n",
    "    fc_w_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-weight_bound, high=weight_bound))\r\n",
    "\r\n",
    "    output = L.fc(input,\r\n",
    "        hidden_size,\r\n",
    "        param_attr=fc_w_attr,\r\n",
    "        name=name,\r\n",
    "        bias_attr=fc_bias_attr)\r\n",
    "    return output\r\n",
    "\r\n",
    "\r\n",
    "def transformer_gat_pgl(gw,\r\n",
    "        feature,\r\n",
    "        hidden_size,\r\n",
    "        name,\r\n",
    "        num_heads=4,\r\n",
    "        attn_drop=0,\r\n",
    "        edge_feature=None,\r\n",
    "        concat=True,\r\n",
    "        is_test=False):\r\n",
    "    '''transformer_gat_pgl\r\n",
    "    '''\r\n",
    "\r\n",
    "    def send_attention(src_feat, dst_feat, edge_feat):\r\n",
    "        if edge_feat is None or not edge_feat:\r\n",
    "            output = src_feat[\"k_h\"] * dst_feat[\"q_h\"]\r\n",
    "            output = L.reduce_sum(output, -1)\r\n",
    "            output = output / (hidden_size ** 0.5)\r\n",
    "            return {\"alpha\": output, \"v\": src_feat[\"v_h\"]}   # batch x h     batch x h x feat\r\n",
    "        else:\r\n",
    "            edge_feat = edge_feat[\"edge\"]\r\n",
    "            edge_feat = L.reshape(edge_feat, [-1, num_heads, hidden_size])\r\n",
    "            output = (src_feat[\"k_h\"] + edge_feat) * dst_feat[\"q_h\"]\r\n",
    "            output = L.reduce_sum(output, -1)\r\n",
    "            output = output / (hidden_size ** 0.5)\r\n",
    "            return {\"alpha\": output, \"v\": (src_feat[\"v_h\"] + edge_feat)}   # batch x h     batch x h x feat\r\n",
    "\r\n",
    "    def reduce_attention(msg):\r\n",
    "        alpha = msg[\"alpha\"]  # lod-tensor (batch_size, seq_len, num_heads)\r\n",
    "        h = msg[\"v\"]\r\n",
    "        alpha = paddle_helper.sequence_softmax(alpha)\r\n",
    "        old_h = h\r\n",
    "        \r\n",
    "        if attn_drop > 1e-15:\r\n",
    "            alpha = L.dropout(\r\n",
    "                alpha,\r\n",
    "                dropout_prob=attn_drop,\r\n",
    "                is_test=is_test,\r\n",
    "                dropout_implementation=\"upscale_in_train\")\r\n",
    "        h = h * alpha\r\n",
    "        h = L.lod_reset(h, old_h)\r\n",
    "        h = L.sequence_pool(h, \"sum\")\r\n",
    "        if concat:\r\n",
    "            h = L.reshape(h, [-1, num_heads * hidden_size])\r\n",
    "        else:\r\n",
    "            h = L.reduce_mean(h, dim=1)\r\n",
    "        return h\r\n",
    "    \r\n",
    "    q_w_attr=F.ParamAttr(initializer=F.initializer.XavierInitializer())\r\n",
    "    q_bias_attr=F.ParamAttr(initializer=F.initializer.ConstantInitializer(0.0))\r\n",
    "    q = L.fc(feature,\r\n",
    "            hidden_size * num_heads,\r\n",
    "            name=name + '_q_weight',\r\n",
    "            param_attr=q_w_attr,\r\n",
    "            bias_attr=q_bias_attr)\r\n",
    "\r\n",
    "    k_w_attr=F.ParamAttr(initializer=F.initializer.XavierInitializer())\r\n",
    "    k_bias_attr=F.ParamAttr(initializer=F.initializer.ConstantInitializer(0.0))\r\n",
    "    k = L.fc(feature,\r\n",
    "            hidden_size * num_heads,\r\n",
    "            name=name + '_k_weight',\r\n",
    "            param_attr=k_w_attr,\r\n",
    "            bias_attr=k_bias_attr)\r\n",
    "\r\n",
    "    v_w_attr=F.ParamAttr(initializer=F.initializer.XavierInitializer())\r\n",
    "    v_bias_attr=F.ParamAttr(initializer=F.initializer.ConstantInitializer(0.0))\r\n",
    "    v = L.fc(feature,\r\n",
    "            hidden_size * num_heads,\r\n",
    "            name=name + '_v_weight',\r\n",
    "            param_attr=v_w_attr,\r\n",
    "            bias_attr=v_bias_attr)\r\n",
    "    \r\n",
    "    reshape_q = L.reshape(q, [-1, num_heads, hidden_size])\r\n",
    "    reshape_k = L.reshape(k, [-1, num_heads, hidden_size])\r\n",
    "    reshape_v = L.reshape(v, [-1, num_heads, hidden_size])\r\n",
    "\r\n",
    "    msg = gw.send(\r\n",
    "        send_attention,\r\n",
    "        nfeat_list=[(\"q_h\", reshape_q), \r\n",
    "                    (\"k_h\", reshape_k),\r\n",
    "                    (\"v_h\", reshape_v)],\r\n",
    "        efeat_list=edge_feature)\r\n",
    "    output = gw.recv(msg, reduce_attention)\r\n",
    "\r\n",
    "    return output\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "import math\r\n",
    "import paddle.fluid.layers as L\r\n",
    "import paddle.fluid as F\r\n",
    "from pgl.utils import paddle_helper\r\n",
    "\r\n",
    "class Model(object):\r\n",
    "    \"\"\"\r\n",
    "    UNIMAP_LABEL_EMBEDDING\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self,dataset,phase):\r\n",
    "        '''\r\n",
    "        UNIMAP_label_embedding\r\n",
    "        '''\r\n",
    "        self.out_size=40\r\n",
    "        self.num_class = dataset.num_classes\r\n",
    "        self.num_layers = config.get(\"num_layers\", 3)\r\n",
    "        self.hidden_size = config.get(\"hidden_size\",128)\r\n",
    "        self.dropout = config.get(\"dropout\", 0.3)\r\n",
    "        self.num_heads = config.get(\"num_heads\", 2)\r\n",
    "        self.edge_dropout = config.get(\"edge_dropout\", 0.0)\r\n",
    "        self.embed_size = 100\r\n",
    "\r\n",
    "        self.gw =pgl.graph_wrapper.GraphWrapper(name=\"graph\",\r\n",
    "                                                node_feat=dataset.graph.node_feat_info())\r\n",
    "        self.node_index = F.data('node_index',\r\n",
    "                                shape=[None,1],\r\n",
    "                                dtype='int64',)\r\n",
    "        self.node_label = F.data(\"node_label\", \r\n",
    "                                shape=[None, 1],\r\n",
    "                                dtype=\"int64\", )\r\n",
    "        self.feature = self.gw.node_feat['feat']\r\n",
    "        self.phase = phase\r\n",
    "\r\n",
    "    def build_model(self):\r\n",
    "        graph_wrapper = self.gw\r\n",
    "        node_label = self.node_label\r\n",
    "        node_index = self.node_index\r\n",
    "        phase = self.phase\r\n",
    "        label_feature = self.label_embed_input(self.feature)\r\n",
    "        if phase == \"train\": \r\n",
    "            edge_dropout = self.edge_dropout\r\n",
    "        else:\r\n",
    "            edge_dropout = 0\r\n",
    "\r\n",
    "        feature_batch = L.dropout(label_feature, dropout_prob=self.dropout, \r\n",
    "                                dropout_implementation='upscale_in_train')\r\n",
    "        for i in range(self.num_layers - 1):\r\n",
    "            feature_batch=self.get_gat_layer(i, graph_wrapper, feature_batch, \r\n",
    "                                             hidden_size=self.hidden_size,\r\n",
    "                                             num_heads=self.num_heads, \r\n",
    "                                             concat=True, \r\n",
    "                                             layer_norm=True, relu=True)#,gate=True)\r\n",
    "            if self.dropout > 0:\r\n",
    "                feature_batch = L.dropout(feature_batch, dropout_prob=self.dropout, \r\n",
    "                                     dropout_implementation='upscale_in_train') \r\n",
    "            \r\n",
    "            \r\n",
    "        feature_batch = self.get_gat_layer(self.num_layers - 1, graph_wrapper, feature_batch, \r\n",
    "                                           hidden_size=self.out_size, num_heads=self.num_heads, \r\n",
    "                                             concat=False, layer_norm=False, relu=False, gate=True)\r\n",
    "        \r\n",
    "        \r\n",
    "        if phase=='train':\r\n",
    "            unlabel_idx = F.data(\"unlabel_idx\",shape=[None],dtype='int64')\r\n",
    "            node_label = fluid.layers.gather(node_label,unlabel_idx)\r\n",
    "            node_index = fluid.layers.gather(node_index,unlabel_idx)\r\n",
    "\r\n",
    "        logits = feature_batch\r\n",
    "        pred = fluid.layers.gather(logits, node_index)\r\n",
    "        loss,pred = fluid.layers.softmax_with_cross_entropy(\r\n",
    "            logits=pred, label=node_label, return_softmax=True)\r\n",
    "        acc = fluid.layers.accuracy(input=pred, label=node_label, k=1)\r\n",
    "        pred = fluid.layers.argmax(pred, -1)\r\n",
    "        loss = fluid.layers.mean(loss)\r\n",
    "\r\n",
    "        if phase == \"train\":\r\n",
    "            adam = fluid.optimizer.Adam(\r\n",
    "                learning_rate=config.learning_rate,\r\n",
    "                regularization=fluid.regularizer.L2DecayRegularizer(\r\n",
    "                    regularization_coeff=config.weight_decay))\r\n",
    "\r\n",
    "            adam.minimize(loss)\r\n",
    "        \r\n",
    "        return loss,acc,pred\r\n",
    "\r\n",
    "    def label_embed_input(self, feature):   \r\n",
    "        label = F.data('train_label',shape=[None,1],dtype='int64')\r\n",
    "        label_idx = F.data(name='label_idx', shape=[None], dtype=\"int64\")\r\n",
    "        label = L.reshape(label, shape=[-1])\r\n",
    "        label = L.gather(label, label_idx, overwrite=False)\r\n",
    "\r\n",
    "        node_idx = F.data('train_index',shape=[None,1],dtype='int64')\r\n",
    "        node_idx = L.gather(node_idx,label_idx,overwrite=False)\r\n",
    "        node_idx = L.reshape(node_idx,shape=[-1])\r\n",
    "\r\n",
    "        embed_attr = F.ParamAttr(initializer=F.initializer.NormalInitializer(loc=0.0, scale=1.0))\r\n",
    "        embed = F.embedding(input=label, size=(self.out_size, self.embed_size), param_attr=embed_attr )\r\n",
    "        \r\n",
    "        feature_label = L.gather(feature, node_idx, overwrite=False)\r\n",
    "        feature_label = feature_label + embed\r\n",
    "        feature = L.scatter(feature, node_idx, feature_label, overwrite=True)\r\n",
    "        \r\n",
    "        \r\n",
    "        lay_norm_attr = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=1))\r\n",
    "        lay_norm_bias = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=0))\r\n",
    "        feature = L.layer_norm(feature, name='layer_norm_feature_input', \r\n",
    "                                      param_attr=lay_norm_attr, \r\n",
    "                                      bias_attr=lay_norm_bias)\r\n",
    "        \r\n",
    "        return feature\r\n",
    "    def get_gat_layer(self, i, gw, feature, hidden_size, num_heads, concat=True,\r\n",
    "                      layer_norm=True, relu=True, gate=False):\r\n",
    "        \r\n",
    "        fan_in = feature.shape[-1]\r\n",
    "        bias_bound = 1.0 / math.sqrt(fan_in)\r\n",
    "        fc_bias_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-bias_bound, high=bias_bound))\r\n",
    "        \r\n",
    "        negative_slope = math.sqrt(5)\r\n",
    "        gain = math.sqrt(2.0 / (1 + negative_slope ** 2))\r\n",
    "        std = gain / math.sqrt(fan_in)\r\n",
    "        weight_bound = math.sqrt(3.0) * std\r\n",
    "        fc_w_attr=F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-weight_bound, high=weight_bound))\r\n",
    "        \r\n",
    "        if concat:\r\n",
    "            skip_feature = L.fc(feature,\r\n",
    "                            hidden_size*num_heads,\r\n",
    "                            param_attr=fc_w_attr,\r\n",
    "                            name='fc_skip_' + str(i),\r\n",
    "                            bias_attr=fc_bias_attr)\r\n",
    "        else:\r\n",
    "            skip_feature = L.fc(feature,\r\n",
    "                            hidden_size,\r\n",
    "                            param_attr=fc_w_attr,\r\n",
    "                            name='fc_skip_' + str(i),\r\n",
    "                            bias_attr=fc_bias_attr)\r\n",
    "        out_feat = transformer_gat_pgl(gw, feature, hidden_size, 'gat_' + str(i), num_heads, concat=concat,) \r\n",
    "\r\n",
    "        \r\n",
    "        if gate: \r\n",
    "          \r\n",
    "            fan_in = out_feat.shape[-1] * 3\r\n",
    "            bias_bound = 1.0 / math.sqrt(fan_in)\r\n",
    "            fc_bias_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-bias_bound, high=bias_bound))\r\n",
    "\r\n",
    "            negative_slope = math.sqrt(5)\r\n",
    "            gain = math.sqrt(2.0 / (1 + negative_slope ** 2))\r\n",
    "            std = gain / math.sqrt(fan_in)\r\n",
    "            weight_bound = math.sqrt(3.0) * std\r\n",
    "            fc_w_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-weight_bound, high=weight_bound))\r\n",
    "\r\n",
    "            \r\n",
    "            \r\n",
    "            gate_f = L.fc([skip_feature, out_feat, out_feat - skip_feature],\r\n",
    "                            1,\r\n",
    "                            param_attr=fc_w_attr,\r\n",
    "                            name='gate_' + str(i),\r\n",
    "                            bias_attr=fc_bias_attr)\r\n",
    "            \r\n",
    "            gate_f = L.sigmoid(gate_f)\r\n",
    "            \r\n",
    "            out_feat = skip_feature * gate_f + out_feat * (1 - gate_f)\r\n",
    "\r\n",
    "        else:\r\n",
    "            out_feat = out_feat + skip_feature\r\n",
    "            \r\n",
    "            \r\n",
    "        if layer_norm:\r\n",
    "            lay_norm_attr = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=1))\r\n",
    "            lay_norm_bias = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=0))\r\n",
    "            out_feat = L.layer_norm(out_feat, name='layer_norm_' + str(i), \r\n",
    "                                      param_attr=lay_norm_attr, \r\n",
    "                                      bias_attr=lay_norm_bias)\r\n",
    "        \r\n",
    "                                     \r\n",
    "        if relu:\r\n",
    "            out_feat = L.relu(out_feat)\r\n",
    "        return out_feat\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pgl\r\n",
    "import paddle.fluid as fluid\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "\r\n",
    "use_cuda =True\r\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n",
    "\r\n",
    "train_program = fluid.Program()\r\n",
    "startup_program = fluid.Program()\r\n",
    "test_program = fluid.Program()\r\n",
    "\r\n",
    "with fluid.program_guard(train_program, startup_program):\r\n",
    "    with fluid.unique_name.guard():\r\n",
    "        model = Model(dataset,'train')\r\n",
    "        loss,acc,pred= model.build_model()\r\n",
    "\r\n",
    "with fluid.program_guard(test_program, startup_program):\r\n",
    "    with fluid.unique_name.guard():\r\n",
    "        model = Model(dataset,'test')\r\n",
    "        v_loss, v_acc, v_pred = model.build_model()\r\n",
    "        \r\n",
    "\r\n",
    "test_program = test_program.clone(for_test=True)\r\n",
    "\r\n",
    "exe = fluid.Executor(place)\r\n",
    "exe.run(startup_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 3000\r\n",
    "\r\n",
    "# 将图数据变成 feed_dict 用于传入Paddle Excecutor\r\n",
    "label_rate = 0.625\r\n",
    "best_val_acc = 0\r\n",
    "index_idx = np.array([*range(len(train_index))])\r\n",
    "feed_dict = model.gw.to_feed(dataset.graph)\r\n",
    "feed_dict[\"train_label\"] = np.array(train_label, dtype=\"int64\")\r\n",
    "feed_dict[\"train_index\"] = np.array(train_index,dtype='int64')\r\n",
    "for epoch in range(epochs):\r\n",
    "    tmp_idx = index_idx\r\n",
    "    np.random.shuffle(tmp_idx)\r\n",
    "    label_idx=tmp_idx[ :int(label_rate*len(tmp_idx))]\r\n",
    "    unlabel_idx= tmp_idx[int(label_rate*len(tmp_idx)): ]\r\n",
    "    feed_dict['label_idx']= np.array(label_idx,dtype='int64')\r\n",
    "    feed_dict[\"unlabel_idx\"]= np.array(unlabel_idx,dtype='int64')\r\n",
    "    feed_dict[\"node_label\"] = np.array(train_label,dtype='int64')\r\n",
    "    feed_dict['node_index'] = np.array(train_index,dtype='int64')\r\n",
    "\r\n",
    "    \r\n",
    "    train_loss,train_acc = exe.run(train_program,\r\n",
    "                    feed=feed_dict,\r\n",
    "                    fetch_list=[loss,acc],\r\n",
    "                    return_numpy=True)\r\n",
    "    feed_dict['label_idx'] = np.array(index_idx,dtype='int64')\r\n",
    "    feed_dict[\"node_index\"] = np.array(val_index, dtype=\"int64\")\r\n",
    "    feed_dict[\"node_label\"] = np.array(val_label, dtype=\"int64\")\r\n",
    "    val_loss, val_acc = exe.run(test_program,\r\n",
    "                            feed=feed_dict,\r\n",
    "                            fetch_list=[v_loss, v_acc],\r\n",
    "                            return_numpy=True)\r\n",
    "    print(\"Epoch\", epoch,\"Train Acc\", train_acc[0],\"Valid Acc\", val_acc[0])\r\n",
    "    if (val_acc[0] > best_val_acc):\r\n",
    "        best_val_acc = val_acc[0]\r\n",
    "        fluid.save(train_program, \"best/best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict[\"node_index\"] = np.array(test_index, dtype=\"int64\")\r\n",
    "feed_dict[\"node_label\"] = np.array(test_label, dtype=\"int64\") #假标签\r\n",
    "fluid.load(test_program,'best/best',exe)\r\n",
    "test_prediction = exe.run(test_program,\r\n",
    "                            feed=feed_dict,\r\n",
    "                            fetch_list=[v_pred],\r\n",
    "                            return_numpy=True)[0]\r\n",
    "print(\"test Acc\", test_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"submission = pd.DataFrame(data={\r\n",
    "                            \"nid\": test_index.reshape(-1),\r\n",
    "                            \"label\": test_prediction.reshape(-1)\r\n",
    "                        })\r\n",
    "submission.to_csv(\"submission_file/{}.csv\".format(best_val_acc), index=False)\r\n",
    "submission.to_csv('submission.csv',index=False)\r\n",
    "print(best_val_acc)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"import csv\r\n",
    "from collections import Counter\r\n",
    "\r\n",
    "def vote_merge(filelst):\r\n",
    "    result = {}\r\n",
    "    fw = open('merge.csv', encoding='utf-8', mode='w', newline='')\r\n",
    "    csv_writer = csv.writer(fw)\r\n",
    "    csv_writer.writerow(['nid', 'label'])\r\n",
    "    for filepath in filelst:\r\n",
    "        cr = open(filepath, encoding='utf-8', mode='r')\r\n",
    "        csv_reader = csv.reader(cr)\r\n",
    "        for i, row in enumerate(csv_reader):\r\n",
    "            if i == 0:\r\n",
    "                continue\r\n",
    "            idx, cls = row\r\n",
    "            if idx not in result:\r\n",
    "                result[idx] = []\r\n",
    "            result[idx].append(cls)\r\n",
    "\r\n",
    "    for nid, clss in result.items():\r\n",
    "        counter = Counter(clss)\r\n",
    "        true_cls = counter.most_common(1)\r\n",
    "        csv_writer.writerow([nid, true_cls[0][0]])\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    vote_merge([\r\n",
    "        # r\"E:\\学习资料\\PGL\\论文节点\\submission_0.715.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.6836.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.7153.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.68744.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.70872.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.71539.csv\",\r\n",
    "                \"E:\\学习资料\\PGL\\论文节点\\submission_val_0.7479889.csv\",\r\n",
    "                \"E:\\学习资料\\PGL\\论文节点\\submission_val_0.74706346.csv\",\r\n",
    "                \"E:\\学习资料\\PGL\\论文节点\\submission_val_0.7459244.csv\",\r\n",
    "                \"E:\\学习资料\\PGL\\论文节点\\submission_val_0.7433616.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.73469.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.725.csv\",\r\n",
    "        #         \"E:\\学习资料\\PGL\\论文节点\\submission_0.721.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.755535.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.7546807.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.75290096.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.75581974.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.7537553.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.7526162.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.7527.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgatii_val_0.75033814.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgatii_val_0.75090766.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.75589097.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.7536129.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.754.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.7548231.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.75596213.csv\",\r\n",
    "        \"E:\\学习资料\\PGL\\论文节点\\submission_resgat_val_0.7563181.csv\",\r\n",
    "                ])\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.4 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
